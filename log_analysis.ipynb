{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba8751f",
   "metadata": {},
   "source": [
    "# PySpark Log File Analysis\n",
    "This notebook parses and analyzes synthetic Apache logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2858e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_extract, col, when\n",
    "spark = SparkSession.builder.appName(\"LogAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = spark.read.text(\"../data/access_log.txt\")\n",
    "pattern = r'^(\\S+) - - \\[(.*?)\\] \"(\\S+) (\\S+) \\S+\" (\\d{3}) (\\d+)'\n",
    "logs = log_df.select(\n",
    "    regexp_extract('value', pattern, 1).alias('ip'),\n",
    "    regexp_extract('value', pattern, 2).alias('timestamp'),\n",
    "    regexp_extract('value', pattern, 3).alias('method'),\n",
    "    regexp_extract('value', pattern, 4).alias('url'),\n",
    "    regexp_extract('value', pattern, 5).cast('int').alias('status'),\n",
    "    regexp_extract('value', pattern, 6).cast('int').alias('size')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top IPs\n",
    "logs.groupBy('ip').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Requested URLs\n",
    "logs.groupBy('url').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Rate Analysis\n",
    "logs = logs.withColumn('error_type', \n",
    "    when((col('status') >= 400) & (col('status') < 500), '4xx')\n",
    "    .when((col('status') >= 500), '5xx')\n",
    "    .otherwise('OK'))\n",
    "logs.groupBy('error_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1928c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
