# Log_analysis_project
My project focuses on parsing and analyzing server log files using Apache Spark (PySpark) to extract meaningful insights from raw log data.
# Log File Analysis with PySpark

My project analyzes synthetic Apache log files using PySpark. Make sure your directory looks like this and then run the jupyter notebook which will generate the data.

## Folder Structure

```
log_analysis_project/
├── data
├── notebooks/
│   └── log_analysis.ipynb
├── scripts/
│   └── generate_logs.py
└── README.md
```

## How to Run

1. Install PySpark:
   ```bash
   pip install pyspark
   ```

2. Start Jupyter Notebook:
Go to the directory, right click there and click on open in terminal and then type:
   ```bash
   jupyter notebook
   ```
This will open the notebook and you can run the cells for operations.
Sample dataset is available in `access_log.txt`.
Make sure you have required installations for this example: python, java etc..
